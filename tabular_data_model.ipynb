{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('/home/janz/PROJECT/Tabular_Datas/processed_data_after_2010.csv')\n",
    "df = pd.read_csv('/home/janz/PROJECT/Tabular_Datas/Tabular_for_cnn_updated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plotting the distribution of the rescaled target variable (Last_UCVA)\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.hist(df['Last_UCVA'], bins=50, edgecolor='k', alpha=0.7)\n",
    "# plt.xlabel('Last_UCVA')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.title('Distribution of Last_UCVA (Rescaled)')\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n",
    "# # Adjust display settings and print the full value counts for detailed distribution\n",
    "# pd.set_option('display.max_rows', None)\n",
    "# print(df['Last_UCVA'].value_counts().sort_index())\n",
    "# pd.reset_option('display.max_rows')  # Reset to default after printing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ocular Treatment ID', 'File', 'Age', 'Gender', 'Eye', 'Dominant Eye', 'Pachymetry', 'PRE-OP Average K', 'Pre-op K  Axis min', 'UCVA', 'Subjective SEQ', 'Subjective Cyl Axis', 'Subjective BCVA', 'Surgery Date', 'Treatment SEQ', 'Treatment Param Axis', 'Opt Zo', 'Max Abl Depth', 'Treatment Type', 'Humidity', 'Temp', 'Op.Time', 'Micro', 'Ring', 'Stop', 'Head', 'Alchohol', 'PTK mmm', 'MZ sec', 'Therapeutic Cont L', 'Rotation Angle Degrees', 'Last_Target Sph', 'Last_UCVA', 'Merge_Contact Lens', 'Season', 'Era', 'Last_Efficacy Index']\n"
     ]
    }
   ],
   "source": [
    "print(list(df))\n",
    "df['Last_UCVA'] = df['Last_UCVA'] * 10\n",
    "df.drop(columns=['Last_Efficacy Index'], inplace=True)\n",
    "df.drop(columns=['Surgery Date'], inplace=True)\n",
    "df.drop(columns=['Op.Time'], inplace=True)\n",
    "df.drop(columns=['Last_Target Sph'], inplace=True)\n",
    "df.drop(columns=['Therapeutic Cont L'], inplace=True)\n",
    "df.drop(columns=['Era'], inplace=True)\n",
    "df.drop(columns=['Season'], inplace=True)\n",
    "df.drop(columns=['Temp'], inplace=True)\n",
    "df.drop(columns=['Humidity'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data (convert non numeric data types to label encoder)\n",
    "label_encoders = {}\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    if col != \"Ocular Treatment ID\":\n",
    "        label_encoders[col] = LabelEncoder()\n",
    "        df[col] = label_encoders[col].fit_transform(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # List of encoded treatment types\n",
    "# treatment_types = [0, 1, 2]  # Femto Lasik, Lasik, PRK\n",
    "\n",
    "# # Initialize dictionaries to hold train, validation, and test data (for each treatment type)\n",
    "# train_data = {}\n",
    "# val_data = {}\n",
    "# test_data = {}\n",
    "\n",
    "# set_seed(42)\n",
    "\n",
    "# # Loop over each treatment type\n",
    "# for treatment_type in treatment_types:\n",
    "#     # Filter data for the current treatment type\n",
    "#     treatment_data = df[df['Treatment Type'] == treatment_type]\n",
    "    \n",
    "#     # Split the data into train and test sets (80% train, 20% test)\n",
    "#     train_data[treatment_type], test_data[treatment_type] = train_test_split(treatment_data, test_size=0.2, random_state=42)\n",
    "    \n",
    "#     # Further split the train data into train and validation sets (80% train, 20% validation)\n",
    "#     train_data[treatment_type], val_data[treatment_type] = train_test_split(train_data[treatment_type], test_size=0.2, random_state=42)\n",
    "\n",
    "# # Concatenate data from all treatment types\n",
    "# train_data_all = pd.concat(train_data.values())\n",
    "# val_data_all = pd.concat(val_data.values())\n",
    "# test_data_all = pd.concat(test_data.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (34247, 28)\n",
      "Validation data shape: (8562, 28)\n",
      "Test data shape: (10703, 28)\n"
     ]
    }
   ],
   "source": [
    "# Filter data based on Last_UCVA values\n",
    "df_above = df[df['Last_UCVA'] > 0.8]\n",
    "df_below = df[df['Last_UCVA'] <= 0.8]\n",
    "\n",
    "# Split data above 0.8 for train and test (80-20 split)\n",
    "train_data_above, test_data_above = train_test_split(df_above, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split data below/equal to 0.8 for train and test (80-20 split)\n",
    "train_data_below, test_data_below = train_test_split(df_below, test_size=0.2, random_state=42)\n",
    "\n",
    "# Further split train data above 0.8 into train and validation (80-20 split)\n",
    "train_data_above, val_data_above = train_test_split(train_data_above, test_size=0.2, random_state=42)\n",
    "\n",
    "# Further split train data below/equal to 0.8 into train and validation (80-20 split)\n",
    "train_data_below, val_data_below = train_test_split(train_data_below, test_size=0.2, random_state=42)\n",
    "\n",
    "# Concatenate data from all splits\n",
    "train_data_all = pd.concat([train_data_above, train_data_below])\n",
    "val_data_all = pd.concat([val_data_above, val_data_below])\n",
    "test_data_all = pd.concat([test_data_above, test_data_below])\n",
    "\n",
    "# Confirm the shapes of your datasets\n",
    "print(f\"Train data shape: {train_data_all.shape}\")\n",
    "print(f\"Validation data shape: {val_data_all.shape}\")\n",
    "print(f\"Test data shape: {test_data_all.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the target columns and also Ocular Treatment ID, File columns\n",
    "X_train = train_data_all.drop(columns=['Last_UCVA', 'Ocular Treatment ID', 'File'])\n",
    "X_val = val_data_all.drop(columns=['Last_UCVA', 'Ocular Treatment ID', 'File'])\n",
    "X_test = test_data_all.drop(columns=['Last_UCVA', 'Ocular Treatment ID', 'File'])\n",
    "\n",
    "# # Extract the target variable\n",
    "y_train = train_data_all['Last_UCVA']\n",
    "y_val = val_data_all['Last_UCVA']\n",
    "y_test = test_data_all['Last_UCVA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Without scaling\n",
    "# X_train_tensor = torch.tensor(X_train.values.astype(np.float32)).to(device)\n",
    "# X_val_tensor = torch.tensor(X_val.values.astype(np.float32)).to(device)\n",
    "# X_test_tensor = torch.tensor(X_test.values.astype(np.float32)).to(device)\n",
    "\n",
    "# With scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train_scaled.astype(np.float32)).to(device)\n",
    "X_val_tensor = torch.tensor(X_val_scaled.astype(np.float32)).to(device)\n",
    "X_test_tensor = torch.tensor(X_test_scaled.astype(np.float32)).to(device)\n",
    "\n",
    "# y tensors (does not matter if with or without scaling, because y labels will not be scaled)\n",
    "y_train_tensor = torch.tensor(y_train.values.astype(np.float32)).unsqueeze(1).to(device)\n",
    "y_val_tensor = torch.tensor(y_val.values.astype(np.float32)).unsqueeze(1).to(device)\n",
    "y_test_tensor = torch.tensor(y_test.values.astype(np.float32)).unsqueeze(1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_epochs = 100\n",
    "batch_size = 64\n",
    "learning_rate = 0.00001 # (high: 1 - 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loaders\n",
    "train_loader = DataLoader(TensorDataset(X_train_tensor, y_train_tensor), batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(TensorDataset(X_val_tensor, y_val_tensor), batch_size=batch_size)\n",
    "test_loader = DataLoader(TensorDataset(X_test_tensor, y_test_tensor), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Net(nn.Module):\n",
    "#     # Start by testing a small network built with layers of 100, 100, 30\n",
    "#     def __init__(self):\n",
    "#         super(Net, self).__init__()\n",
    "#         self.fc1 = nn.Linear(X_train_tensor.shape[1], 100)\n",
    "#         self.dropout1 = nn.Dropout(0.1)  # Add dropout layer with 20% dropout rate\n",
    "#         self.fc2 = nn.Linear(100, 100)\n",
    "#         self.dropout2 = nn.Dropout(0.05)  # Add dropout layer with 20% dropout rate\n",
    "#         self.fc3 = nn.Linear(100, 30)\n",
    "#         self.fc4 = nn.Linear(30, 1)\n",
    "#         self.feature_extractor = nn.Linear(30, 30)  # Assuming feature_extractor is needed\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = self.dropout1(x)  # Apply dropout after the first hidden layer\n",
    "#         x = F.relu(self.fc2(x))\n",
    "#         x = self.dropout2(x)  # Apply dropout after the second hidden layer\n",
    "#         x = F.relu(self.fc3(x))\n",
    "#         features = self.feature_extractor(x)  # Extract intermediate features\n",
    "#         output = self.fc4(x)\n",
    "#         return features, output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(X_train_tensor.shape[1], 64)  # Increased neurons\n",
    "        self.dropout1 = nn.Dropout(0.185)\n",
    "        self.fc2 = nn.Linear(64, 128)  # Increased neurons\n",
    "        self.dropout2 = nn.Dropout(0.185)\n",
    "        self.fc3 = nn.Linear(128, 256)  # Increased neurons\n",
    "        self.dropout3 = nn.Dropout(0.185)\n",
    "        self.fc4 = nn.Linear(256, 128)  # Increased neurons\n",
    "        self.dropout4 = nn.Dropout(0.185)\n",
    "        self.fc5 = nn.Linear(128, 64)  # Increased neurons\n",
    "        self.fc6 = nn.Linear(64, 1)\n",
    "        self.feature_extractor = nn.Linear(64, 64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.dropout3(x)\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.dropout4(x)\n",
    "        x = F.relu(self.fc5(x))\n",
    "        features = self.feature_extractor(x)\n",
    "        output = self.fc6(x)\n",
    "        return features, output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TEST RESULTS PLAYGROUND**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, roc_auc_score\n",
    "from tabulate import tabulate# Define different threshold configurations for evaluation\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# class Net(nn.Module):\n",
    "#     def __init__(self, input_size, dropout_rate):\n",
    "#         super(Net, self).__init__()\n",
    "#         self.fc1 = nn.Linear(input_size, 64)\n",
    "#         self.dropout1 = nn.Dropout(dropout_rate)\n",
    "#         self.fc2 = nn.Linear(64, 128)\n",
    "#         self.dropout2 = nn.Dropout(dropout_rate)\n",
    "#         self.fc3 = nn.Linear(128, 256)\n",
    "#         self.dropout3 = nn.Dropout(dropout_rate)\n",
    "#         self.fc4 = nn.Linear(256, 128)\n",
    "#         self.dropout4 = nn.Dropout(dropout_rate)\n",
    "#         self.fc5 = nn.Linear(128, 64)\n",
    "#         self.fc6 = nn.Linear(64, 1)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = self.dropout1(x)\n",
    "#         x = F.relu(self.fc2(x))\n",
    "#         x = self.dropout2(x)\n",
    "#         x = F.relu(self.fc3(x))\n",
    "#         x = self.dropout3(x)\n",
    "#         x = F.relu(self.fc4(x))\n",
    "#         x = self.dropout4(x)\n",
    "#         x = F.relu(self.fc5(x))\n",
    "#         x = self.fc6(x)\n",
    "#         return x\n",
    "    \n",
    "class Net(nn.Module):\n",
    "    # Start by testing a small network built with layers of 100, 100, 30\n",
    "    def __init__(self, input_size, dropout_rate):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 100)\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)  # Add dropout layer with 20% dropout rate\n",
    "        self.fc2 = nn.Linear(100, 100)\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)  # Add dropout layer with 20% dropout rate\n",
    "        self.fc3 = nn.Linear(100, 30)\n",
    "        self.fc4 = nn.Linear(30, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)  # Apply dropout after the first hidden layer\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)  # Apply dropout after the second hidden layer\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "# Function for training the model\n",
    "def train_model(config):\n",
    "    # Unpack configuration\n",
    "    num_epochs = config['num_epochs']\n",
    "    batch_size = config['batch_size']\n",
    "    learning_rate = config['learning_rate']\n",
    "    dropout_rate = config['dropout_rate']\n",
    "\n",
    "    # Initialize model, loss function, optimizer, and scheduler\n",
    "    model = Net(input_size=X_train_tensor.shape[1], dropout_rate=dropout_rate).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)\n",
    "    \n",
    "    train_loader = DataLoader(TensorDataset(X_train_tensor, y_train_tensor), batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(TensorDataset(X_val_tensor, y_val_tensor), batch_size=batch_size)\n",
    "    test_loader = DataLoader(TensorDataset(X_test_tensor, y_test_tensor), batch_size=batch_size)\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    patience = 4\n",
    "    epochs_without_improvement = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        set_seed(42)\n",
    "        print(f\"Epoch {epoch} from {num_epochs}\")\n",
    "        model.train()\n",
    "        running_train_loss = 0.0\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_train_loss += loss.item() * inputs.size(0)\n",
    "        train_loss = running_train_loss / len(train_loader.dataset)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        running_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                running_val_loss += loss.item() * inputs.size(0)\n",
    "        val_loss = running_val_loss / len(val_loader.dataset)\n",
    "        scheduler.step(val_loss)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        if  val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_without_improvement = 0\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "            if epochs_without_improvement > patience:\n",
    "                print(f'Early stopping at epoch {epoch}')\n",
    "                break\n",
    "\n",
    "    return model, {\n",
    "        'train_loss': train_losses[-1],\n",
    "        'val_loss': val_losses[-1]\n",
    "    }\n",
    "\n",
    "# Function for evaluating the model with different thresholds\n",
    "def evaluate_model(model, config):\n",
    "    test_loader = DataLoader(TensorDataset(X_test_tensor, y_test_tensor), batch_size=config['batch_size'])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        total_mae = 0.0\n",
    "        total_mse = 0.0\n",
    "        all_predictions = []\n",
    "        all_targets = []\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            total_mae += torch.mean(torch.abs(outputs - targets)).item()\n",
    "            total_mse += torch.mean((outputs - targets) ** 2).item()\n",
    "            all_predictions.extend(outputs.cpu().numpy().flatten())\n",
    "            all_targets.extend(targets.cpu().numpy().flatten())\n",
    "        mae = total_mae / len(test_loader)\n",
    "        mse = total_mse / len(test_loader)\n",
    "\n",
    "    all_predictions = np.array(all_predictions)\n",
    "    all_targets = np.array(all_targets)\n",
    "    abs_difference = np.abs(all_predictions - all_targets)\n",
    "    abs_difference_mask = abs_difference <= config['abs_difference_threshold']\n",
    "\n",
    "    binary_predictions = np.where(all_predictions >= config['binary_classification_threshold'], 1, 0)\n",
    "    binary_targets = np.where(all_targets >= config['binary_classification_threshold'], 1, 0)\n",
    "    for i in range(len(binary_predictions)):\n",
    "        if abs_difference_mask[i]:\n",
    "            binary_predictions[i] = binary_targets[i]\n",
    "\n",
    "    precision = precision_score(binary_targets, binary_predictions)\n",
    "    recall = recall_score(binary_targets, binary_predictions)\n",
    "    accuracy = accuracy_score(binary_targets, binary_predictions)\n",
    "    auc = roc_auc_score(binary_targets, binary_predictions)\n",
    "    true_negatives = np.sum((binary_targets == 0) & (binary_predictions == 0))\n",
    "    false_positives = np.sum((binary_targets == 0) & (binary_predictions == 1))\n",
    "    false_alarm_rate = false_positives / (false_positives + true_negatives)\n",
    "\n",
    "    return {\n",
    "        'mae': mae,\n",
    "        'mse': mse,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'accuracy': accuracy,\n",
    "        'auc': auc,\n",
    "        'false_alarm_rate': false_alarm_rate,\n",
    "        'config': config  # Include configuration in the results\n",
    "    }\n",
    "\n",
    "# Define the training configuration\n",
    "training_config = {\n",
    "    'num_epochs': 100,\n",
    "    'batch_size': 64,\n",
    "    'learning_rate': 0.00001,\n",
    "    'dropout_rate': 0.185\n",
    "}\n",
    "\n",
    "# Train the model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Assuming X_train_tensor, y_train_tensor, X_val_tensor, y_val_tensor, X_test_tensor, y_test_tensor are already defined\n",
    "trained_model, training_results = train_model(training_config)\n",
    "print(f\"Training results: {training_results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define different threshold configurations for evaluation\n",
    "threshold_configs = [\n",
    "    {\n",
    "        'binary_classification_threshold': 9.25,\n",
    "        'abs_difference_threshold': 0,\n",
    "        'dropout_rate': training_config['dropout_rate'],\n",
    "        'batch_size': training_config['batch_size'],\n",
    "        'num_epochs': training_config['num_epochs'],\n",
    "        'learning_rate': training_config['learning_rate']\n",
    "    },\n",
    "    {\n",
    "        'binary_classification_threshold': 9.25,\n",
    "        'abs_difference_threshold': 1,\n",
    "        'dropout_rate': training_config['dropout_rate'],\n",
    "        'batch_size': training_config['batch_size'],\n",
    "        'num_epochs': training_config['num_epochs'],\n",
    "        'learning_rate': training_config['learning_rate']\n",
    "    },\n",
    "    {\n",
    "        'binary_classification_threshold': 9,\n",
    "        'abs_difference_threshold': 0,\n",
    "        'dropout_rate': training_config['dropout_rate'],\n",
    "        'batch_size': training_config['batch_size'],\n",
    "        'num_epochs': training_config['num_epochs'],\n",
    "        'learning_rate': training_config['learning_rate']\n",
    "    },\n",
    "    {\n",
    "        'binary_classification_threshold': 9,\n",
    "        'abs_difference_threshold': 1,\n",
    "        'dropout_rate': training_config['dropout_rate'],\n",
    "        'batch_size': training_config['batch_size'],\n",
    "        'num_epochs': training_config['num_epochs'],\n",
    "        'learning_rate': training_config['learning_rate']\n",
    "    },\n",
    "    {\n",
    "        'binary_classification_threshold': 8.5,\n",
    "        'abs_difference_threshold': 0,\n",
    "        'dropout_rate': training_config['dropout_rate'],\n",
    "        'batch_size': training_config['batch_size'],\n",
    "        'num_epochs': training_config['num_epochs'],\n",
    "        'learning_rate': training_config['learning_rate']\n",
    "    },\n",
    "    {\n",
    "        'binary_classification_threshold': 8.5,\n",
    "        'abs_difference_threshold': 1,\n",
    "        'dropout_rate': training_config['dropout_rate'],\n",
    "        'batch_size': training_config['batch_size'],\n",
    "        'num_epochs': training_config['num_epochs'],\n",
    "        'learning_rate': training_config['learning_rate']\n",
    "    },\n",
    "    {\n",
    "        'binary_classification_threshold': 8,\n",
    "        'abs_difference_threshold': 0,\n",
    "        'dropout_rate': training_config['dropout_rate'],\n",
    "        'batch_size': training_config['batch_size'],\n",
    "        'num_epochs': training_config['num_epochs'],\n",
    "        'learning_rate': training_config['learning_rate']\n",
    "    },\n",
    "    {\n",
    "        'binary_classification_threshold': 8,\n",
    "        'abs_difference_threshold': 1,\n",
    "        'dropout_rate': training_config['dropout_rate'],\n",
    "        'batch_size': training_config['batch_size'],\n",
    "        'num_epochs': training_config['num_epochs'],\n",
    "        'learning_rate': training_config['learning_rate']\n",
    "    }\n",
    "]\n",
    "\n",
    "# threshold_configs = [\n",
    "#     {\n",
    "#         'binary_classification_threshold': 9.25,\n",
    "#         'abs_difference_threshold': 0,\n",
    "#         'batch_size': training_config['batch_size']\n",
    "#     },\n",
    "#     {\n",
    "#         'binary_classification_threshold': 9.25,\n",
    "#         'abs_difference_threshold': 1,\n",
    "#         'batch_size': training_config['batch_size']\n",
    "#     },\n",
    "#     {\n",
    "#         'binary_classification_threshold': 9,\n",
    "#         'abs_difference_threshold': 0,\n",
    "#         'batch_size': training_config['batch_size']\n",
    "#     },\n",
    "#     {\n",
    "#         'binary_classification_threshold': 9,\n",
    "#         'abs_difference_threshold': 1,\n",
    "#         'batch_size': training_config['batch_size']\n",
    "#     },\n",
    "#     {\n",
    "#         'binary_classification_threshold': 8.5,\n",
    "#         'abs_difference_threshold': 0,\n",
    "#         'batch_size': training_config['batch_size']\n",
    "#     },\n",
    "#     {\n",
    "#         'binary_classification_threshold': 8.5,\n",
    "#         'abs_difference_threshold': 1,\n",
    "#         'batch_size': training_config['batch_size']\n",
    "#     },\n",
    "#     {\n",
    "#         'binary_classification_threshold': 8,\n",
    "#         'abs_difference_threshold': 0,\n",
    "#         'batch_size': training_config['batch_size']\n",
    "#     },\n",
    "#     {\n",
    "#         'binary_classification_threshold': 8,\n",
    "#         'abs_difference_threshold': 1,\n",
    "#         'batch_size': training_config['batch_size']\n",
    "#     }\n",
    "# ]\n",
    "\n",
    "# Evaluate the model with different thresholds\n",
    "evaluation_results = []\n",
    "for config in threshold_configs:\n",
    "    results = evaluate_model(trained_model, config)\n",
    "    evaluation_results.append(results)\n",
    "\n",
    "# Convert results to DataFrame and print as table\n",
    "results_df = pd.DataFrame(evaluation_results)\n",
    "# Print configurations as well\n",
    "results_df['config'] = results_df['config'].apply(lambda x: str(x))\n",
    "print(tabulate(results_df, headers='keys', tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Training Loss: 81.3145, Validation Loss: 65.3991\n",
      "Epoch [2/100], Training Loss: 24.1423, Validation Loss: 6.1267\n",
      "Epoch [3/100], Training Loss: 6.7319, Validation Loss: 5.0616\n",
      "Epoch [4/100], Training Loss: 5.9655, Validation Loss: 4.4986\n",
      "Epoch [5/100], Training Loss: 5.4948, Validation Loss: 4.1400\n",
      "Epoch [6/100], Training Loss: 5.1733, Validation Loss: 3.8936\n",
      "Epoch [7/100], Training Loss: 4.9363, Validation Loss: 3.7148\n",
      "Epoch [8/100], Training Loss: 4.7506, Validation Loss: 3.5793\n",
      "Epoch [9/100], Training Loss: 4.5979, Validation Loss: 3.4736\n",
      "Epoch [10/100], Training Loss: 4.4678, Validation Loss: 3.3890\n",
      "Epoch [11/100], Training Loss: 4.3542, Validation Loss: 3.3200\n",
      "Epoch [12/100], Training Loss: 4.2529, Validation Loss: 3.2631\n",
      "Epoch [13/100], Training Loss: 4.1612, Validation Loss: 3.2155\n",
      "Epoch [14/100], Training Loss: 4.0772, Validation Loss: 3.1751\n",
      "Epoch [15/100], Training Loss: 4.0002, Validation Loss: 3.1404\n",
      "Epoch [16/100], Training Loss: 3.9290, Validation Loss: 3.1103\n",
      "Epoch [17/100], Training Loss: 3.8631, Validation Loss: 3.0844\n",
      "Epoch [18/100], Training Loss: 3.8018, Validation Loss: 3.0617\n",
      "Epoch [19/100], Training Loss: 3.7447, Validation Loss: 3.0418\n",
      "Epoch [20/100], Training Loss: 3.6911, Validation Loss: 3.0241\n",
      "Epoch [21/100], Training Loss: 3.6408, Validation Loss: 3.0090\n",
      "Epoch [22/100], Training Loss: 3.5936, Validation Loss: 2.9954\n",
      "Epoch [23/100], Training Loss: 3.5493, Validation Loss: 2.9837\n",
      "Epoch [24/100], Training Loss: 3.5076, Validation Loss: 2.9737\n",
      "Epoch [25/100], Training Loss: 3.4683, Validation Loss: 2.9654\n",
      "Epoch [26/100], Training Loss: 3.4313, Validation Loss: 2.9585\n",
      "Epoch [27/100], Training Loss: 3.3964, Validation Loss: 2.9526\n",
      "Epoch [28/100], Training Loss: 3.3634, Validation Loss: 2.9472\n",
      "Epoch [29/100], Training Loss: 3.3321, Validation Loss: 2.9426\n",
      "Epoch [30/100], Training Loss: 3.3025, Validation Loss: 2.9383\n",
      "Epoch [31/100], Training Loss: 3.2745, Validation Loss: 2.9346\n",
      "Epoch [32/100], Training Loss: 3.2480, Validation Loss: 2.9316\n",
      "Epoch [33/100], Training Loss: 3.2228, Validation Loss: 2.9293\n",
      "Epoch [34/100], Training Loss: 3.1990, Validation Loss: 2.9277\n",
      "Epoch [35/100], Training Loss: 3.1763, Validation Loss: 2.9264\n",
      "Epoch [36/100], Training Loss: 3.1547, Validation Loss: 2.9255\n",
      "Epoch [37/100], Training Loss: 3.1341, Validation Loss: 2.9250\n",
      "Epoch [38/100], Training Loss: 3.1146, Validation Loss: 2.9247\n",
      "Epoch [39/100], Training Loss: 3.0960, Validation Loss: 2.9245\n",
      "Epoch [40/100], Training Loss: 3.0782, Validation Loss: 2.9246\n",
      "Epoch [41/100], Training Loss: 3.0613, Validation Loss: 2.9250\n",
      "Epoch [42/100], Training Loss: 3.0451, Validation Loss: 2.9253\n",
      "Epoch [43/100], Training Loss: 3.0296, Validation Loss: 2.9258\n",
      "Epoch [44/100], Training Loss: 3.0147, Validation Loss: 2.9262\n",
      "Epoch [45/100], Training Loss: 3.0005, Validation Loss: 2.9342\n",
      "Epoch [46/100], Training Loss: 2.9991, Validation Loss: 2.9340\n",
      "Early stopping at epoch 45\n"
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# model, loss function, and optimizer\n",
    "model = Net().to(device)\n",
    "criterion = nn.MSELoss() # MSE (Mean Squared Error)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0) # Adam is used as an optimizer# Train the model (high: 0.1 - 0.001)\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)\n",
    "\n",
    "# Save losses for further analysis\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "patience = 6\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    set_seed(42)\n",
    "    model.train()\n",
    "    running_train_loss = 0.0\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        # outputs = model(inputs)\n",
    "        features, outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_train_loss += loss.item() * inputs.size(0)\n",
    "    train_loss = running_train_loss / len(train_loader.dataset)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    model.eval()\n",
    "    running_val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            # outputs = model(inputs)\n",
    "            features, outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            running_val_loss += loss.item() * inputs.size(0)\n",
    "    val_loss = running_val_loss / len(val_loader.dataset)\n",
    "    scheduler.step(val_loss)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}')\n",
    "\n",
    "    if  val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        epochs_without_improvement = 0\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "        if epochs_without_improvement > patience:\n",
    "            print(f'Early stopping at epoch {epoch}')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, roc_auc_score\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Define your loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "def objective(trial):\n",
    "    set_seed(42)\n",
    "    # Define hyperparameters to be optimized\n",
    "    lr = trial.suggest_float('lr', 1e-6, 1e-1, log=True)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64, 128, 8])\n",
    "    \n",
    "    # Create dataset and dataloaders with the suggested batch size\n",
    "    train_loader = DataLoader(TensorDataset(X_train_tensor, y_train_tensor), batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(TensorDataset(X_val_tensor, y_val_tensor), batch_size=batch_size)\n",
    "    # test_loader = DataLoader(TensorDataset(X_test_tensor, y_test_tensor), batch_size=batch_size)\n",
    "\n",
    "    set_seed(42)\n",
    "\n",
    "    # Load pre-trained DenseNet model and modify the final layer\n",
    "    model = Net().to(device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    \n",
    "    # Define the learning rate scheduler if needed\n",
    "    # scheduler = StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "    set_seed(42)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    patience = 6\n",
    "    epochs_without_improvement = 0\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(30):\n",
    "        set_seed(42)\n",
    "        model.train()\n",
    "        running_train_loss = 0.0\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            # outputs = model(inputs)\n",
    "            _, outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_train_loss += loss.item() * inputs.size(0)\n",
    "        train_loss = running_train_loss / len(train_loader.dataset)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        running_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                # outputs = model(inputs)\n",
    "                _, outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                running_val_loss += loss.item() * inputs.size(0)\n",
    "        val_loss = running_val_loss / len(val_loader.dataset)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        if  val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_without_improvement = 0\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "            if epochs_without_improvement > patience:\n",
    "                print(f'Early stopping at epoch {epoch}')\n",
    "                break\n",
    "\n",
    "    # Initialize lists to store predictions and true values\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "\n",
    "    # Test the model\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            # inputs = inputs.to(device) \n",
    "            _, outputs = model(inputs)\n",
    "            outputs = outputs.cpu().numpy().flatten()\n",
    "            targets = targets.cpu().numpy().flatten()\n",
    "            # Store predictions and true values for evaluation\n",
    "            all_predictions.extend(outputs)\n",
    "            # print(all_predictions)\n",
    "            all_targets.extend(targets)\n",
    "\n",
    "    # Convert predictions and targets to numpy arrays\n",
    "    all_predictions = np.array(all_predictions)\n",
    "    all_targets = np.array(all_targets)\n",
    "\n",
    "    binary_classification_threshold = 8.5\n",
    "    abs_difference_threshold = 1\n",
    "\n",
    "    # Check if the absolute difference is smaller than the threshold\n",
    "    abs_difference = np.abs(all_predictions - all_targets)\n",
    "    abs_difference_mask = abs_difference <= abs_difference_threshold\n",
    "\n",
    "    # Convert to binary classification based on threshold\n",
    "    binary_predictions = np.where(all_predictions >= binary_classification_threshold, 1, 0)\n",
    "    # print(binary_predictions)\n",
    "    binary_targets = np.where(all_targets >= binary_classification_threshold, 1, 0)\n",
    "    # print(binary_targets)\n",
    "\n",
    "    for i in range(len(binary_predictions)):\n",
    "        if abs_difference_mask[i] == True:\n",
    "            binary_predictions[i] = binary_targets[i]\n",
    "\n",
    "    # Calculate precision, recall, accuracy, and AUC\n",
    "    precision = precision_score(binary_targets, binary_predictions)\n",
    "    recall = recall_score(binary_targets, binary_predictions)\n",
    "    accuracy = accuracy_score(binary_targets, binary_predictions)\n",
    "    auc = roc_auc_score(binary_targets, binary_predictions)\n",
    "\n",
    "    print(f'Test Precision: {precision:.4f}, Recall: {recall:.4f}, Accuracy: {accuracy:.4f}, AUC: {auc:.4f}')\n",
    "\n",
    "    # Calculate false alarm rate (FPR)\n",
    "    # False alarm rate = false positives / (false positives + true negatives)\n",
    "    true_negatives = np.sum((binary_targets == 0) & (binary_predictions == 0))\n",
    "    false_positives = np.sum((binary_targets == 0) & (binary_predictions == 1))\n",
    "    false_alarm_rate = false_positives / (false_positives + true_negatives)\n",
    "\n",
    "    print(f'False Alarm Rate: {false_alarm_rate:.4f}')\n",
    "    \n",
    "    return auc\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "print('Best trial:', study.best_trial.params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = len(train_losses)  # Update to reflect the actual number of epochs trained, useful if early stopping was triggered\n",
    "\n",
    "def smooth_curve(points, factor=0.8):\n",
    "    \"\"\"Smooths the curve for better visualization.\"\"\"\n",
    "    smoothed_points = []\n",
    "    for point in points:\n",
    "        if smoothed_points:\n",
    "            previous = smoothed_points[-1]\n",
    "            smoothed_points.append(previous * factor + point * (1 - factor))\n",
    "        else:\n",
    "            smoothed_points.append(point)\n",
    "    return smoothed_points\n",
    "\n",
    "# Optionally smooth the loss curves\n",
    "train_losses_smooth = smooth_curve(train_losses)\n",
    "val_losses_smooth = smooth_curve(val_losses)\n",
    "\n",
    "plt.figure(figsize=(10, 5))  # Set the figure size for better readability\n",
    "plt.plot(range(1, num_epochs + 1), train_losses_smooth, label='Training Loss')\n",
    "plt.plot(range(1, num_epochs + 1), val_losses_smooth, label='Validation Loss')\n",
    "plt.title('Training and Validation Loss Curves')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)  # Add grid\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 1.3123\n",
      "Mean Squared Error (MSE): 3.0524\n"
     ]
    }
   ],
   "source": [
    "# Calculate Mean Absolute Error (MAE)\n",
    "with torch.no_grad():\n",
    "    total_mae = 0.0\n",
    "    for inputs, targets in test_loader:\n",
    "        # outputs = model(inputs)\n",
    "        features, outputs = model(inputs)\n",
    "        total_mae += torch.mean(torch.abs(outputs - targets)).item()\n",
    "    mae = total_mae / len(test_loader)\n",
    "\n",
    "print(f'Mean Absolute Error (MAE): {mae:.4f}')\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "with torch.no_grad():\n",
    "    total_mse = 0.0\n",
    "    for inputs, targets in test_loader:\n",
    "        # outputs = model(inputs)\n",
    "        features, outputs = model(inputs)\n",
    "        total_mse += torch.mean((outputs - targets) ** 2).item()\n",
    "    mse = total_mse / len(test_loader)\n",
    "\n",
    "print(f'Mean Squared Error (MSE): {mse:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Precision: 0.9206, Recall: 0.7749, Accuracy: 0.7617, AUC: 0.7388\n",
      "False Alarm Rate: 0.2974\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, roc_auc_score\n",
    "\n",
    "# Initialize lists to store predictions and true values\n",
    "all_predictions = []\n",
    "all_targets = []\n",
    "\n",
    "# Test the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        # inputs = inputs.to(device) \n",
    "        # outputs = model(inputs)\n",
    "        features, outputs = model(inputs)\n",
    "        outputs = outputs.cpu().numpy().flatten()\n",
    "        targets = targets.cpu().numpy().flatten()\n",
    "        # Store predictions and true values for evaluation\n",
    "        all_predictions.extend(outputs)\n",
    "        # print(all_predictions)\n",
    "        all_targets.extend(targets)\n",
    "\n",
    "# Convert predictions and targets to numpy arrays\n",
    "all_predictions = np.array(all_predictions)\n",
    "all_targets = np.array(all_targets)\n",
    "\n",
    "binary_classification_threshold = 8.5\n",
    "abs_difference_threshold = 1\n",
    "\n",
    "# Check if the absolute difference is smaller than the threshold\n",
    "abs_difference = np.abs(all_predictions - all_targets)\n",
    "abs_difference_mask = abs_difference <= abs_difference_threshold\n",
    "\n",
    "# Convert to binary classification based on threshold\n",
    "binary_predictions = np.where(all_predictions >= binary_classification_threshold, 1, 0)\n",
    "# print(binary_predictions)\n",
    "binary_targets = np.where(all_targets >= binary_classification_threshold, 1, 0)\n",
    "# print(binary_targets)\n",
    "\n",
    "for i in range(len(binary_predictions)):\n",
    "    if abs_difference_mask[i] == True:\n",
    "        binary_predictions[i] = binary_targets[i]\n",
    "\n",
    "# Calculate precision, recall, accuracy, and AUC\n",
    "precision = precision_score(binary_targets, binary_predictions)\n",
    "recall = recall_score(binary_targets, binary_predictions)\n",
    "accuracy = accuracy_score(binary_targets, binary_predictions)\n",
    "auc = roc_auc_score(binary_targets, binary_predictions)\n",
    "\n",
    "print(f'Test Precision: {precision:.4f}, Recall: {recall:.4f}, Accuracy: {accuracy:.4f}, AUC: {auc:.4f}')\n",
    "\n",
    "# Calculate false alarm rate (FPR)\n",
    "# False alarm rate = false positives / (false positives + true negatives)\n",
    "true_negatives = np.sum((binary_targets == 0) & (binary_predictions == 0))\n",
    "false_positives = np.sum((binary_targets == 0) & (binary_predictions == 1))\n",
    "false_alarm_rate = false_positives / (false_positives + true_negatives)\n",
    "\n",
    "print(f'False Alarm Rate: {false_alarm_rate:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Precision: 0.9184, Recall: 0.7852, Accuracy: 0.7676, AUC: 0.7373\n",
    "\n",
    "False Alarm Rate: 0.3106"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP model saved to /home/janz/PROJECT/trained_models/mlp_model.pth\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "mlp_model_path = \"/home/janz/PROJECT/trained_models/mlp_model.pth\"\n",
    "torch.save(model.state_dict(), mlp_model_path)\n",
    "print(f\"MLP model saved to {mlp_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_predictions[:30])\n",
    "print(all_targets[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the histogram\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.hist(all_predictions, bins=50, edgecolor='k', alpha=0.7)\n",
    "plt.title('Distribution of Predictions')\n",
    "plt.xlabel('Predicted Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plotting the histogram\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.hist(all_targets, bins=50, edgecolor='k', alpha=0.7)\n",
    "plt.title('Distribution of actual Targets')\n",
    "plt.xlabel('Predicted Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and display the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "cm = confusion_matrix(binary_targets, binary_predictions)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Plot the confusion matrix using seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 8\n",
    "above = 0\n",
    "lower = 0\n",
    "# for i in df[\"Last_UCVA\"]:\n",
    "for i in all_targets:\n",
    "    if i >= thresh:\n",
    "        above += 1\n",
    "    else:\n",
    "        lower += 1\n",
    "print(f\"There is {above} samples which there target value are above the value of {thresh}\")\n",
    "print(f\"There is {lower} samples which there target value are under the value of {thresh}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "np.random.seed(42)\n",
    "\n",
    "# Initialize the SHAP GradientExplainer\n",
    "background = X_train_tensor[:]  # Adjust this based on your dataset size and diversity\n",
    "gradient_explainer = shap.GradientExplainer(model, background)\n",
    "\n",
    "# Choose a specific instance to explain\n",
    "instance_to_explain = X_train_tensor[0:1]  # Using a slice to keep the tensor's dimension\n",
    "\n",
    "# Calculate SHAP values for this instance\n",
    "shap_values = gradient_explainer.shap_values(instance_to_explain)\n",
    "\n",
    "# If model is a classifier and shap_values is a list, take the first element\n",
    "if isinstance(shap_values, list):\n",
    "    shap_values = shap_values[0]\n",
    "\n",
    "# Reshape SHAP values to remove unnecessary dimensions\n",
    "shap_values = shap_values.squeeze()\n",
    "\n",
    "# Convert the instance to numpy array for visualization\n",
    "instance_numpy = instance_to_explain.detach().cpu().numpy()\n",
    "\n",
    "# Calculate the expected value (mean output over the background data)\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    background_predictions = model(background)\n",
    "    expected_value = background_predictions.mean().item()\n",
    "\n",
    "\n",
    "# print(\"SHAP values for the instance:\")\n",
    "# for name, value in zip(list(X_train.columns), shap_values):\n",
    "#     print(f\"{name}: {value:.4f}\")\n",
    "# print(\"Expected value of the model output:\", expected_value)\n",
    "\n",
    "# # Optionally print other diagnostics\n",
    "# print(\"Shape of SHAP values:\", shap_values.shape)\n",
    "# print(\"Shape of the instance data:\", instance_numpy.shape)\n",
    "\n",
    "\n",
    "# Plotting the waterfall chart for the first prediction\n",
    "\n",
    "shap.waterfall_plot(shap.Explanation(values=shap_values,  # Reshaped SHAP values\n",
    "                                     base_values=expected_value,  # Computed expected value\n",
    "                                     data=instance_numpy[0],  # The specific instance being explained\n",
    "                                     feature_names=list(X_train.columns)), max_display=10)  # Actual feature names\n",
    "\n",
    "shap_values = shap_values.reshape(1, -1)\n",
    "\n",
    "shap.summary_plot(shap_values, instance_to_explain, plot_type=\"bar\", feature_names=X_train.columns, max_display=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, roc_auc_score\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Define a threshold for binary classification\n",
    "binary_classification_threshold = 8\n",
    "abs_difference_threshold = 0\n",
    "\n",
    "# Define and train XGBoost model\n",
    "xgb_model = xgb.XGBRegressor(n_estimators=100, use_label_encoder=False)\n",
    "xgb_model.fit(X_train_scaled, y_train.values)\n",
    "\n",
    "# Test XGBoost model\n",
    "y_pred = xgb_model.predict(X_test_scaled)\n",
    "\n",
    "# Check if the absolute difference is smaller than the threshold\n",
    "abs_difference = np.abs(y_pred - y_test.values)\n",
    "abs_difference_mask = abs_difference <= abs_difference_threshold\n",
    "\n",
    "# Convert probabilities to binary predictions based on threshold\n",
    "binary_predictions_xgb = np.where(y_pred >= binary_classification_threshold, 1, 0)\n",
    "# Convert target variable to binary labels based on the threshold for test set\n",
    "binary_y_test = np.where(y_test >= binary_classification_threshold, 1, 0)\n",
    "\n",
    "for i in range(len(binary_predictions_xgb)):\n",
    "    if abs_difference_mask[i] == True:\n",
    "        binary_predictions_xgb[i] = binary_y_test[i]\n",
    "\n",
    "# Calculate precision, recall, accuracy, and AUC for XGBoost model on test data\n",
    "precision_xgb = precision_score(binary_y_test, binary_predictions_xgb)\n",
    "recall_xgb = recall_score(binary_y_test, binary_predictions_xgb)\n",
    "accuracy_xgb = accuracy_score(binary_y_test, binary_predictions_xgb)\n",
    "auc_xgb = roc_auc_score(binary_y_test, binary_predictions_xgb)\n",
    "\n",
    "true_negatives_xgb = np.sum((binary_y_test == 0) & (binary_predictions_xgb == 0))\n",
    "false_positives_xgb = np.sum((binary_y_test == 0) & (binary_predictions_xgb == 1))\n",
    "false_alarm_rate_xgb = false_positives_xgb / (false_positives_xgb + true_negatives_xgb)\n",
    "\n",
    "# Print evaluation metrics for XGBoost model\n",
    "print(f'XGBoost Test Precision: {precision_xgb:.4f}, Recall: {recall_xgb:.4f}, Accuracy: {accuracy_xgb:.4f}, AUC: {auc_xgb:.4f}')\n",
    "print(f'False Alarm Rate: {false_alarm_rate_xgb:.4f}')\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Define Random Forest model\n",
    "rf_model = RandomForestRegressor(n_estimators=100)\n",
    "\n",
    "# Train Random Forest model\n",
    "rf_model.fit(X_train_scaled, y_train.values)\n",
    "\n",
    "# Test Random Forest model\n",
    "y_pred_rf = rf_model.predict(X_test_scaled)\n",
    "\n",
    "# Check if the absolute difference is smaller than the threshold\n",
    "abs_difference = np.abs(y_pred_rf - y_test.values)\n",
    "abs_difference_mask = abs_difference <= abs_difference_threshold\n",
    "\n",
    "# Convert probabilities to binary predictions based on threshold\n",
    "binary_predictions_rf = np.where(y_pred_rf >= binary_classification_threshold, 1, 0)\n",
    "# Convert target variable to binary labels based on the threshold for test set\n",
    "binary_y_test = np.where(y_test >= binary_classification_threshold, 1, 0)\n",
    "\n",
    "for i in range(len(binary_predictions_rf)):\n",
    "    if abs_difference_mask[i] == True:\n",
    "        binary_predictions_rf[i] = binary_y_test[i]\n",
    "\n",
    "# Calculate precision, recall, accuracy, and AUC for Random Forest model on test data\n",
    "precision_rf = precision_score(binary_y_test, binary_predictions_rf)\n",
    "recall_rf = recall_score(binary_y_test, binary_predictions_rf)\n",
    "accuracy_rf = accuracy_score(binary_y_test, binary_predictions_rf)\n",
    "auc_rf = roc_auc_score(binary_y_test, binary_predictions_rf)\n",
    "\n",
    "true_negatives_rf = np.sum((binary_y_test == 0) & (binary_predictions_rf == 0))\n",
    "false_positives_rf = np.sum((binary_y_test == 0) & (binary_predictions_rf == 1))\n",
    "false_alarm_rate_rf = false_positives_rf / (false_positives_rf + true_negatives_rf)\n",
    "\n",
    "# Print evaluation metrics for Random Forest model\n",
    "print(f'Random Forest Test Precision: {precision_rf:.4f}, Recall: {recall_rf:.4f}, Accuracy: {accuracy_rf:.4f}, AUC: {auc_rf:.4f}')\n",
    "print(f'False Alarm Rate: {false_alarm_rate_rf:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost Test Precision: 0.9017, Recall: 0.9524, Accuracy: 0.8704, AUC: 0.6688\n",
    "\n",
    "False Alarm Rate: 0.6147\n",
    "\n",
    "Random Forest Test Precision: 0.9072, Recall: 0.9450, Accuracy: 0.8702, AUC: 0.6864\n",
    "\n",
    "False Alarm Rate: 0.5721"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create a SHAP explainer object using TreeExplainer for XGBoost model\n",
    "explainer_xgb = shap.TreeExplainer(xgb_model)\n",
    "shap_values_xgb = explainer_xgb.shap_values(X_test_scaled)\n",
    "\n",
    "# Plotting the SHAP values for XGBoost model\n",
    "shap.summary_plot(shap_values_xgb, X_test_scaled, plot_type=\"bar\", feature_names=X_train.columns, max_display=10)\n",
    "\n",
    "# Compute the mean SHAP values across all instances\n",
    "mean_shap_values_xgb = np.mean(shap_values_xgb, axis=0)\n",
    "\n",
    "# Plotting the waterfall plot for the aggregated SHAP values\n",
    "shap.waterfall_plot(shap.Explanation(values=mean_shap_values_xgb, base_values=explainer_xgb.expected_value, data=X_test_scaled.mean(axis=0), feature_names=X_train.columns), max_display=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a SHAP explainer object using TreeExplainer for Random Forest model\n",
    "# explainer_rf = shap.TreeExplainer(rf_model)\n",
    "# shap_values_rf = explainer_rf.shap_values(X_test_scaled)\n",
    "# # Plotting the SHAP values for Random Forest model\n",
    "# # Plotting the SHAP values for XGBoost model\n",
    "# shap.summary_plot(shap_values_rf, X_test_scaled, plot_type=\"bar\", feature_names=X_train.columns)\n",
    "\n",
    "# # Compute the mean SHAP values across all instances\n",
    "# mean_shap_values_xgb = np.mean(shap_values_rf, axis=0)\n",
    "\n",
    "# # Plotting the waterfall plot for the aggregated SHAP values\n",
    "# shap.waterfall_plot(shap.Explanation(values=mean_shap_values_xgb, base_values=explainer_xgb.expected_value, data=X_test_scaled.mean(axis=0), feature_names=X_train.columns), max_display=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set option to display all columns\n",
    "# pd.set_option('display.max_columns', None)\n",
    "\n",
    "# # Set option to display all rows\n",
    "# pd.set_option('display.max_rows', None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
